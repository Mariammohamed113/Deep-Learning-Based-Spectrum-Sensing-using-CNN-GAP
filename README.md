# Deep-Learning-Based-Spectrum-Sensing-using-CNN-GAP
Deep Learningâ€‘Based Spectrum Sensing using CNN and GAP Layers
This project implements a complete binary spectrum sensing system capable of identifying whether the received I/Q signal frame contains:

Primary User (PU) signal
Noise only (no PU)

The system uses 1D CNN architectures, featureâ€‘optimized layers, and robust dataset filtering to achieve highly accurate detection under various SNR conditions.

ğŸ“Œ Overview
This work focuses on building a reliable spectrum sensing pipeline using deepâ€‘learning CNN models trained on raw 1024â€‘sample I/Q signals.
The goal is to create a fast, lightweight, highâ€‘accuracy model capable of generalizing across modulation types and noisy environments.

ğŸ§© Signal Processing & Feature Handling
The system processes radio signals using:
ğŸ”¹ I/Q Raw Input Handling
Utilizes the inâ€‘phase and quadrature (I/Q) samples provided by the dataset.
ğŸ”¹ AWGN Noise Augmentation
Adds controlledâ€‘standardâ€‘deviation noise (Ïƒ = 0.708) dynamically during training.
ğŸ”¹ HDF5 Data Pipeline
Efficient sample loading, sorted indexing, and batched generators for highâ€‘speed training.
ğŸ”¹ SNR Filtering
Training uses only SNR â‰¥ â€“8 dB, eliminating noiseâ€‘dominated frames that harm accuracy.

âš™ï¸ Model Architecture
The project implements two CNN architectures:
ğŸ”¹ CNN + Flatten Layer

Multiple Conv1D + MaxPooling layers
Dense classifier
High accuracy but prone to overfitting

ğŸ”¹ CNN + Global Average Pooling (GAP)

Replaces flatten layer with GAP
Reduces parameters drastically
Improves generalization
Enhances detection performance across modulation types

Both models output a binary classification:
Signal present (1) / Noise (0)

ğŸ¤– Training Setup

Trained on filtered RadioML dataset (I/Q: 1024Ã—2 samples)
Uses Adam optimizer
Batch size: 2048
Epochs: 32â€“40 depending on configuration
HDF5â€‘based generator ensures memoryâ€‘safe training
ModelCheckpoint + ReduceLROnPlateau callbacks included


ğŸ“Š Evaluation Metrics
Each model is evaluated using:

Accuracy
Loss curves (train/val)
Detection Probability (Pd) vs SNR
Performance across modulation types
Comparison with traditional sensing methods

The system consistently outperforms:

Maximumâ€“Minimum Eigenvalue Ratio method
Frequencyâ€‘Domain Entropy detection


ğŸ” SNRâ€‘Based Performance Analysis
Evaluation includes:

Pd curves for multiple modulations (e.g., OOK, QPSK)
Behavior under extremely low SNR conditions
Identification of SNR thresholds where PU presence becomes detectable

The model achieves:

97.5%â€“98% detection accuracy depending on architecture
Strong robustness against AWGN
Excellent generalization across unseen modulations


ğŸ“ Automated Plotting & Visualization
The system automatically generates:

Training accuracy curves
Training loss curves
Final Pd vs SNR plots
Modulationâ€‘wise performance graphs

Plots are saved to the configured output directory.

ğŸ“‚ Project Structure
/src
    data_loader.py
    gap_model.py
    flatten_model.py
    generator.py
    train.py
    evaluate.py

/data
    (Place HDF5 dataset here)

plots/
checkpoints/
README.md


ğŸš€ Future Enhancements

Hardware deployment on SDR platforms
Multiâ€‘class spectrum classification
Hybrid CNNâ€‘RNN architectures
Transfer learning for unseen modulation types
Realâ€‘time inference optimization


ğŸ“œ License
Open for academic and research usage.

ğŸ‘¤ Author
Developed by Mariam Mohamed
